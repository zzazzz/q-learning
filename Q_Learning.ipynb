{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library"
      ],
      "metadata": {
        "id": "0V1Pv-YKYFlR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61bI3-adSzmW",
        "outputId": "d2e21441-7673-4615-9415-6e23ec2b6ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.2/1.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.25.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.17.3 --quiet\n",
        "import numpy as np\n",
        "import gym\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Membuat Peta"
      ],
      "metadata": {
        "id": "7ujGHeeBYIbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat daftar peta\n",
        "peta = [\n",
        "    ['SFFF','FHFH','FFFH','HFFG'],\n",
        "    ['SFFF','FFHF','HFFF','HFFG'],\n",
        "    ['SHFF','FHFH','FFFH','HHFG'],\n",
        "    ['SFFF','HHFF','FFFF','HFFG'],\n",
        "    ['SFFH','FFFH','HFFH','HHFG']\n",
        "]"
      ],
      "metadata": {
        "id": "gwrOd23vS2vE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peta[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TxE3pSwVXPf",
        "outputId": "a1120639-ea95-4cae-d48a-96a6e719e4e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SFFF', 'FHFH', 'FFFH', 'HFFG']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat lingkungan\n",
        "env = gym.make(\"FrozenLake-v0\",is_slippery=False, desc=peta[0])"
      ],
      "metadata": {
        "id": "Sihxapo5TO3-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_observations = env.observation_space.n\n",
        "n_actions      = env.action_space.n\n",
        "\n",
        "print('Banyak State  : ' + str(n_observations))\n",
        "print('Banyak Action : ' + str(n_actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSO2jZRCTBTY",
        "outputId": "81a18f7a-b589-4c45-bb73-64fb669d3b74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banyak State  : 16\n",
            "Banyak Action : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACTION = [\"KIRI\",\"BAWAH\",\"KANAN\",\"ATAS\"]"
      ],
      "metadata": {
        "id": "9tWgK357TDWl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMic7ZCyUOAR",
        "outputId": "50377ee4-bf25-4c17-e697-69a33fd971ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Menguji Langkah Agen"
      ],
      "metadata": {
        "id": "nEqse2iqYThU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 1 (ke Kanan)\n",
        "new_state, reward, done, info = env.step(2)\n",
        "\n",
        "# Menampilkan informasi\n",
        "print(f\"New State : {new_state}\")\n",
        "print(f\"Reward    : {reward}\")\n",
        "print(f\"Done      : {done}\")\n",
        "\n",
        "# Menampilkan visualisasi lingkungan\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYtR3y9XUU3U",
        "outputId": "54a31bd1-da3f-4e22-a368-a16d6dcace27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 1\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 2 (ke Kanan)\n",
        "new_state, reward, done, info = env.step(2)\n",
        "\n",
        "# Menampilkan informasi\n",
        "print(f\"New State : {new_state}\")\n",
        "print(f\"Reward    : {reward}\")\n",
        "print(f\"Done      : {done}\")\n",
        "\n",
        "# Menampilkan visualisasi lingkungan\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sxKu0DhU2cn",
        "outputId": "6bf5007a-13e1-42b3-87a8-f094d9907cd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 2\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3 (ke Bawah)\n",
        "new_state, reward, done, info = env.step(1)\n",
        "\n",
        "# Menampilkan informasi\n",
        "print('New State : {}'.format(new_state))\n",
        "print('Reward    : {}'.format(reward))\n",
        "print('Done      : {}'.format(done))\n",
        "\n",
        "# Menampilkan visualisasi lingkungan\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5p0wJ7RVIfI",
        "outputId": "5b00bc13-73a3-427a-a3de-8f8feeb5a017"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 6\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 4 (ke Bawah)\n",
        "new_state, reward, done, info = env.step(1)\n",
        "\n",
        "# Menampilkan informasi\n",
        "print('New State : {}'.format(new_state))\n",
        "print('Reward    : {}'.format(reward))\n",
        "print('Done      : {}'.format(done))\n",
        "\n",
        "# Menampilkan visualisasi lingkungan\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGSur5ufVVBU",
        "outputId": "b888931e-9ae3-4db4-ed9b-645c24c9cb61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 10\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 5 (ke Bawah)\n",
        "new_state, reward, done, info = env.step(1)\n",
        "\n",
        "# Menampilkan informasi\n",
        "print(f\"New State : {new_state}\")\n",
        "print(f\"Reward    : {reward}\")\n",
        "print(f\"Done      : {done}\")\n",
        "\n",
        "# Menampilkan visualisasi lingkungan\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGMGMW2TVifi",
        "outputId": "4d9e22a5-0a01-44c9-ac9c-fbebb52be920"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 14\n",
            "Reward    : 0.0\n",
            "Done      : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 6 (ke Kanan)\n",
        "new_state, reward, done, info = env.step(2)\n",
        "\n",
        "# Menampilkan informasi\n",
        "print(f\"New State : {new_state}\")\n",
        "print(f\"Reward    : {reward}\")\n",
        "print(f\"Done      : {done}\")\n",
        "\n",
        "# Menampilkan visualisasi lingkungan\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHuyr14VVou6",
        "outputId": "90f698b3-993b-4cff-8000-8b82a8af27e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New State : 15\n",
            "Reward    : 1.0\n",
            "Done      : True\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model"
      ],
      "metadata": {
        "id": "lkINAxSRYZy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agent(env, n_episodes=10000, max_iter_episode=100, exploration_proba=1, exploration_decreasing_decay=0.001, min_exploration_proba=0.01, gamma=0.99, lr=0.1):\n",
        "    # Inisialisasi Q-table dengan ukuran berdasarkan jumlah state dan aksi\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "\n",
        "    # List untuk menyimpan reward dari setiap episode\n",
        "    rewards_per_episode = []\n",
        "\n",
        "    # Loop melalui setiap episode\n",
        "    for episode in range(n_episodes):\n",
        "        # Reset lingkungan untuk memulai episode baru dan mendapatkan state awal\n",
        "        state = env.reset()\n",
        "\n",
        "        # Inisialisasi total reward episode menjadi 0\n",
        "        episode_reward = 0\n",
        "\n",
        "        # Loop melalui setiap iterasi dalam episode\n",
        "        for _ in range(max_iter_episode):\n",
        "            # Pilih tindakan berdasarkan probabilitas eksplorasi atau menggunakan kebijakan Q\n",
        "            if np.random.uniform(0, 1) < exploration_proba:\n",
        "                action = env.action_space.sample()  # Aksi acak (eksplorasi)\n",
        "            else:\n",
        "                action = np.argmax(Q_table[state, :])  # Aksi terbaik berdasarkan Q-table (eksploitasi)\n",
        "\n",
        "            # Ambil langkah berdasarkan tindakan yang dipilih\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "            # Update Q-value berdasarkan reward yang diterima dan perkiraan nilai Q di state berikutnya\n",
        "            Q_table[state, action] = (1 - lr) * Q_table[state, action] + lr * (reward + gamma * np.max(Q_table[next_state, :]))\n",
        "\n",
        "            # Tambahkan reward dari langkah ini ke total reward episode\n",
        "            episode_reward += reward\n",
        "            state = next_state  # Pindah ke state berikutnya\n",
        "\n",
        "            # Hentikan episode jika mencapai terminal state\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Kurangi probabilitas eksplorasi seiring berjalannya waktu\n",
        "        exploration_proba = max(min_exploration_proba, np.exp(-exploration_decreasing_decay * episode))\n",
        "\n",
        "        # Simpan total reward episode ke dalam list\n",
        "        rewards_per_episode.append(episode_reward)\n",
        "\n",
        "    # Cetak rata-rata reward per 1000 episode\n",
        "    print(\"Rata-Rata Reward per 1000 Episode\")\n",
        "    for i in range(10):\n",
        "        print((i + 1) * 1000, \" : Rata-Rata Reward: \", np.mean(rewards_per_episode[1000 * i:1000 * (i + 1)]))\n",
        "\n",
        "    # Kembalikan Q-table yang telah dilatih\n",
        "    return Q_table"
      ],
      "metadata": {
        "id": "V8fjx3i2VrIi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q_table_all = []  # List kosong untuk menyimpan semua tabel Q dari setiap lingkungan\n",
        "\n",
        "for peta_env in peta:  # Loop melalui setiap peta dalam daftar peta\n",
        "    # Load Environment untuk setiap peta dengan konfigurasi tertentu\n",
        "    env = gym.make(\"FrozenLake-v0\", is_slippery=False, desc=peta_env)\n",
        "    env.reset()  # Reset lingkungan ke keadaan awal\n",
        "\n",
        "    print('Peta : ')\n",
        "    print(peta_env)  # Cetak peta yang sedang digunakan\n",
        "\n",
        "    # Melatih Agent pada lingkungan saat ini\n",
        "    Q_table = train_agent(env)  # Panggil fungsi train_agent untuk melatih agen di lingkungan saat ini\n",
        "\n",
        "    # Menyimpan Q_table untuk lingkungan saat ini ke dalam list\n",
        "    Q_table_all.append(Q_table)  # Tambahkan Q_table ke dalam list Q_table_all\n",
        "\n",
        "    print()  # Cetak baris kosong untuk pemisah antara lingkungan yang berbeda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzzLU_vPWAxW",
        "outputId": "9df0c3a5-c213-4e2f-d0e8-406ec6f86a2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peta : \n",
            "['SFFF', 'FHFH', 'FFFH', 'HFFG']\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.276\n",
            "2000  : Rata-Rata Reward:  0.729\n",
            "3000  : Rata-Rata Reward:  0.911\n",
            "4000  : Rata-Rata Reward:  0.967\n",
            "5000  : Rata-Rata Reward:  0.993\n",
            "6000  : Rata-Rata Reward:  0.991\n",
            "7000  : Rata-Rata Reward:  0.988\n",
            "8000  : Rata-Rata Reward:  0.99\n",
            "9000  : Rata-Rata Reward:  0.979\n",
            "10000  : Rata-Rata Reward:  0.989\n",
            "\n",
            "Peta : \n",
            "['SFFF', 'FFHF', 'HFFF', 'HFFG']\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.292\n",
            "2000  : Rata-Rata Reward:  0.778\n",
            "3000  : Rata-Rata Reward:  0.913\n",
            "4000  : Rata-Rata Reward:  0.965\n",
            "5000  : Rata-Rata Reward:  0.992\n",
            "6000  : Rata-Rata Reward:  0.992\n",
            "7000  : Rata-Rata Reward:  0.991\n",
            "8000  : Rata-Rata Reward:  0.993\n",
            "9000  : Rata-Rata Reward:  0.987\n",
            "10000  : Rata-Rata Reward:  0.991\n",
            "\n",
            "Peta : \n",
            "['SHFF', 'FHFH', 'FFFH', 'HHFG']\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.0\n",
            "2000  : Rata-Rata Reward:  0.0\n",
            "3000  : Rata-Rata Reward:  0.0\n",
            "4000  : Rata-Rata Reward:  0.0\n",
            "5000  : Rata-Rata Reward:  0.0\n",
            "6000  : Rata-Rata Reward:  0.0\n",
            "7000  : Rata-Rata Reward:  0.0\n",
            "8000  : Rata-Rata Reward:  0.0\n",
            "9000  : Rata-Rata Reward:  0.0\n",
            "10000  : Rata-Rata Reward:  0.0\n",
            "\n",
            "Peta : \n",
            "['SFFF', 'HHFF', 'FFFF', 'HFFG']\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.39\n",
            "2000  : Rata-Rata Reward:  0.81\n",
            "3000  : Rata-Rata Reward:  0.922\n",
            "4000  : Rata-Rata Reward:  0.985\n",
            "5000  : Rata-Rata Reward:  0.992\n",
            "6000  : Rata-Rata Reward:  0.992\n",
            "7000  : Rata-Rata Reward:  0.998\n",
            "8000  : Rata-Rata Reward:  0.988\n",
            "9000  : Rata-Rata Reward:  0.994\n",
            "10000  : Rata-Rata Reward:  0.996\n",
            "\n",
            "Peta : \n",
            "['SFFH', 'FFFH', 'HFFH', 'HHFG']\n",
            "Rata-Rata Reward per 1000 Episode\n",
            "1000  : Rata-Rata Reward:  0.319\n",
            "2000  : Rata-Rata Reward:  0.775\n",
            "3000  : Rata-Rata Reward:  0.94\n",
            "4000  : Rata-Rata Reward:  0.971\n",
            "5000  : Rata-Rata Reward:  0.992\n",
            "6000  : Rata-Rata Reward:  0.992\n",
            "7000  : Rata-Rata Reward:  0.995\n",
            "8000  : Rata-Rata Reward:  0.994\n",
            "9000  : Rata-Rata Reward:  0.992\n",
            "10000  : Rata-Rata Reward:  0.997\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_table_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LoRuCE8WHik",
        "outputId": "0abe8bb5-7f0b-49c7-b095-10af19aa1128"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.94148015, 0.95099005, 0.93206535, 0.94148015],\n",
              "        [0.94148015, 0.        , 0.74063515, 0.87055359],\n",
              "        [0.87660457, 0.21674049, 0.0517229 , 0.04142206],\n",
              "        [0.22374726, 0.        , 0.00917317, 0.00828988],\n",
              "        [0.95099005, 0.96059601, 0.        , 0.94148015],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.86976285, 0.        , 0.11154469],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.960596  , 0.        , 0.970299  , 0.95099005],\n",
              "        [0.96059587, 0.9801    , 0.98009995, 0.        ],\n",
              "        [0.84404355, 0.99      , 0.        , 0.63373197],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.98009989, 0.99      , 0.97029887],\n",
              "        [0.98009821, 0.98999977, 1.        , 0.98009575],\n",
              "        [0.        , 0.        , 0.        , 0.        ]]),\n",
              " array([[0.94148015, 0.95099005, 0.95099005, 0.94148015],\n",
              "        [0.93670872, 0.96059601, 0.90928756, 0.94511364],\n",
              "        [0.94302246, 0.        , 0.05445693, 0.55762385],\n",
              "        [0.08538064, 0.15854999, 0.04110558, 0.03791783],\n",
              "        [0.95099005, 0.        , 0.96059601, 0.94148015],\n",
              "        [0.95099005, 0.970299  , 0.        , 0.95099005],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.51488852, 0.10628966, 0.01442802],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.9801    , 0.98009998, 0.960596  ],\n",
              "        [0.93531273, 0.99      , 0.87152426, 0.        ],\n",
              "        [0.39503566, 0.97496844, 0.19585044, 0.10259637],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.98009999, 0.99      , 0.97029885],\n",
              "        [0.98009989, 0.98999987, 1.        , 0.98009584],\n",
              "        [0.        , 0.        , 0.        , 0.        ]]),\n",
              " array([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]]),\n",
              " array([[0.94148015, 0.        , 0.95099005, 0.94148015],\n",
              "        [0.94148015, 0.        , 0.96059601, 0.95099005],\n",
              "        [0.95099004, 0.97029899, 0.970299  , 0.96059599],\n",
              "        [0.96059601, 0.9801    , 0.970299  , 0.970299  ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.9214048 , 0.9801    , 0.94310836],\n",
              "        [0.970299  , 0.99      , 0.9801    , 0.970299  ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.49674199, 0.        ],\n",
              "        [0.14750829, 0.02676572, 0.98999998, 0.77305521],\n",
              "        [0.98009935, 1.        , 0.99      , 0.9801    ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.02444878],\n",
              "        [0.        , 0.        , 0.        , 0.263584  ],\n",
              "        [0.        , 0.        , 0.        , 0.        ]]),\n",
              " array([[0.94148015, 0.95099005, 0.95099005, 0.94148015],\n",
              "        [0.94148015, 0.96059601, 0.96059601, 0.95099005],\n",
              "        [0.94795462, 0.970299  , 0.        , 0.95161748],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.93560693, 0.        , 0.96059601, 0.93781017],\n",
              "        [0.95099005, 0.970299  , 0.970299  , 0.95099005],\n",
              "        [0.96059601, 0.9801    , 0.        , 0.96059601],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.9801    , 0.94054611],\n",
              "        [0.970299  , 0.99      , 0.        , 0.970299  ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.98999972, 1.        , 0.98009992],\n",
              "        [0.        , 0.        , 0.        , 0.        ]])]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memainkan Agen yang Telah Dilatih\n"
      ],
      "metadata": {
        "id": "2cvaIMZKYgVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_peta = 0 # silakan pilih peta\n",
        "\n",
        "env = gym.make(\"FrozenLake-v0\",is_slippery=False, desc=peta[index_peta])\n",
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfdu4tGIWwWZ",
        "outputId": "b2d589c6-544e-4d09-c0aa-d4878d342ab3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for langkah in range(1, 7):\n",
        "    if langkah == 1:\n",
        "        best_action = np.argmax(Q_table_all[index_peta][0])\n",
        "    else:\n",
        "        best_action = np.argmax(Q_table_all[index_peta][current_state])\n",
        "\n",
        "    new_state, reward, done, info = env.step(best_action)\n",
        "\n",
        "    # Cetak informasi langkah\n",
        "    print('--------------------------------------')\n",
        "    print('Langkah ke  :', langkah)\n",
        "    print('Best Action :', ACTION[best_action])\n",
        "    print('New State   :', new_state)\n",
        "    print('Reward      :', reward)\n",
        "    print('Done        :', done)\n",
        "\n",
        "    # Tampilkan visualisasi lingkungan\n",
        "    env.render()\n",
        "    current_state = new_state  # Perbarui state saat ini\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGpSfHHqXMi1",
        "outputId": "d5de4126-4500-42a2-b15e-f167fb2138fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "Langkah ke  : 1\n",
            "Best Action : KANAN\n",
            "New State   : 1\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "--------------------------------------\n",
            "Langkah ke  : 2\n",
            "Best Action : KANAN\n",
            "New State   : 2\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "--------------------------------------\n",
            "Langkah ke  : 3\n",
            "Best Action : BAWAH\n",
            "New State   : 6\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "--------------------------------------\n",
            "Langkah ke  : 4\n",
            "Best Action : BAWAH\n",
            "New State   : 10\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "\n",
            "--------------------------------------\n",
            "Langkah ke  : 5\n",
            "Best Action : BAWAH\n",
            "New State   : 14\n",
            "Reward      : 0.0\n",
            "Done        : False\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "\n",
            "--------------------------------------\n",
            "Langkah ke  : 6\n",
            "Best Action : KANAN\n",
            "New State   : 15\n",
            "Reward      : 1.0\n",
            "Done        : True\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluasi"
      ],
      "metadata": {
        "id": "eH-vYXPtYlzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for peta_env in peta:  # Iterasi melalui setiap peta dalam daftar peta\n",
        "    print(\"Peta   :\", peta_env)  # Cetak deskripsi peta yang sedang diperiksa\n",
        "\n",
        "    env = gym.make(\"FrozenLake-v0\", is_slippery=False, desc=peta_env)  # Buat lingkungan permainan Frozen Lake\n",
        "    env.reset()  # Atur ulang lingkungan ke keadaan awal\n",
        "\n",
        "    # Iterasi untuk agen melakukan langkah-langkah dalam lingkungan\n",
        "    for langkah in range(1, 7):\n",
        "        if langkah == 1:\n",
        "            best_action = np.argmax(Q_table_all[index_peta][0])  # Ambil tindakan terbaik untuk langkah pertama\n",
        "        else:\n",
        "            best_action = np.argmax(Q_table_all[index_peta][current_state])  # Ambil tindakan terbaik berdasarkan state saat ini\n",
        "\n",
        "        new_state, reward, done, info = env.step(best_action)  # Lakukan langkah terbaik dalam lingkungan\n",
        "\n",
        "        current_state = new_state  # Perbarui state saat ini\n",
        "\n",
        "    # Periksa apakah agen berhasil menyelesaikan permainan\n",
        "    if done:\n",
        "        print(\"Status : Agent dapat menyelesaikan peta ini\")  # Cetak pesan jika agen berhasil menyelesaikan permainan\n",
        "    else:\n",
        "        print(\"Status : Agent tidak dapat menyelesaikan peta ini\")  # Cetak pesan jika agen gagal menyelesaikan permainan\n",
        "\n",
        "    print()  # Cetak baris kosong sebagai pemisah antara hasil dari setiap peta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N45KSOpPXZ0K",
        "outputId": "74c22fbd-4477-4e47-cf8f-6cedceeb75be"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peta   : ['SFFF', 'FHFH', 'FFFH', 'HFFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SFFF', 'FFHF', 'HFFF', 'HFFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SHFF', 'FHFH', 'FFFH', 'HHFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SFFF', 'HHFF', 'FFFF', 'HFFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n",
            "Peta   : ['SFFH', 'FFFH', 'HFFH', 'HHFG']\n",
            "Status : Agent dapat menyelesaikan peta ini\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Menyimpan Model"
      ],
      "metadata": {
        "id": "tp-srbbsYpYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan tabel Q yang telah dilatih menggunakan modul pickle\n",
        "pickle.dump(Q_table_all, open('Q_table_Frozen_Lake.model', 'wb'))\n",
        "\n",
        "# Penjelasan penutup\n",
        "print(\"Tabel Q untuk lingkungan Frozen Lake telah berhasil disimpan dalam file 'Q_table_Frozen_Lake.model'. Proses pelatihan agen dan penyimpanan tabel Q ini memungkinkan untuk digunakan kembali dalam pengujian atau aplikasi selanjutnya tanpa perlu melakukan pelatihan ulang.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXgNi0M7XlRV",
        "outputId": "fbab324d-9817-4eb3-b0e1-61afc338885f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabel Q untuk lingkungan Frozen Lake telah berhasil disimpan dalam file 'Q_table_Frozen_Lake.model'. Proses pelatihan agen dan penyimpanan tabel Q ini memungkinkan untuk digunakan kembali dalam pengujian atau aplikasi selanjutnya tanpa perlu melakukan pelatihan ulang.\n"
          ]
        }
      ]
    }
  ]
}